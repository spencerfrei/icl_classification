{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating checkpoints/checkpoint_d100_B100_R5_20241119_095938_step_300.pt\n",
      "\n",
      "Evaluating curves for d=100, label_flip_p=0.2\n",
      "Position 20: memorization = 0.951, test = 0.570\n",
      "\n",
      "Evaluating checkpoints/checkpoint_d50_B50_R3_20241119_095938_step_300.pt\n",
      "\n",
      "Evaluating curves for d=50, label_flip_p=0.2\n",
      "Position 20: memorization = 0.884, test = 0.600\n",
      "\n",
      "Evaluating checkpoints/checkpoint_d100_B100_R5_20241119_095938_step_300.pt\n",
      "\n",
      "Evaluating curves for d=100, label_flip_p=0.2\n",
      "Position 20: memorization = 0.949, test = 0.603\n",
      "\n",
      "Evaluating checkpoints/checkpoint_d2000_B2000_R14_20241119_120146_step_300.pt\n",
      "\n",
      "Evaluating curves for d=2000, label_flip_p=0.2\n",
      "Position 20: memorization = 1.000, test = 0.557\n",
      "\n",
      "Evaluating checkpoints/checkpoint_d400_B400_R8_20241119_095941_step_300.pt\n",
      "\n",
      "Evaluating curves for d=400, label_flip_p=0.2\n",
      "Position 20: memorization = 0.999, test = 0.573\n",
      "\n",
      "Evaluating checkpoints/checkpoint_d600_B600_R9_20241119_095946_step_300.pt\n",
      "\n",
      "Evaluating curves for d=600, label_flip_p=0.2\n",
      "Position 20: memorization = 1.000, test = 0.555\n",
      "\n",
      "Evaluating checkpoints/checkpoint_d800_B800_R10_20241119_095958_step_300.pt\n",
      "\n",
      "Evaluating curves for d=800, label_flip_p=0.2\n",
      "Position 20: memorization = 1.000, test = 0.556\n",
      "\n",
      "Evaluating checkpoints/checkpoint_d1000_B1000_R11_20241119_100020_step_300.pt\n",
      "\n",
      "Evaluating curves for d=1000, label_flip_p=0.2\n",
      "Position 20: memorization = 1.000, test = 0.559\n",
      "\n",
      "Evaluating checkpoints/checkpoint_d1250_B1250_R12_20241119_100101_step_300.pt\n",
      "\n",
      "Evaluating curves for d=1250, label_flip_p=0.2\n",
      "Position 20: memorization = 1.000, test = 0.559\n",
      "\n",
      "Evaluating checkpoints/checkpoint_d1500_B1500_R12_20241119_100211_step_300.pt\n",
      "\n",
      "Evaluating curves for d=1500, label_flip_p=0.2\n",
      "Position 20: memorization = 1.000, test = 0.544\n",
      "\n",
      "Evaluating checkpoints/checkpoint_d2000_B2000_R14_20241119_120146_step_300.pt\n",
      "\n",
      "Evaluating curves for d=2000, label_flip_p=0.2\n",
      "Position 20: memorization = 1.000, test = 0.569\n",
      "Saved plot for label_flip_p=0.2 to plots/dimension_curves_N20_R0.1_p0.2.png\n",
      "\n",
      "Evaluating checkpoints/checkpoint_d100_B100_R5_20241119_095938_step_300.pt\n",
      "\n",
      "Evaluating curves for d=100, label_flip_p=0.2\n",
      "Position 20: memorization = 0.942, test = 0.646\n",
      "\n",
      "Evaluating checkpoints/checkpoint_d50_B50_R3_20241119_095938_step_300.pt\n",
      "\n",
      "Evaluating curves for d=50, label_flip_p=0.2\n",
      "Position 20: memorization = 0.840, test = 0.756\n",
      "\n",
      "Evaluating checkpoints/checkpoint_d100_B100_R5_20241119_095938_step_300.pt\n",
      "\n",
      "Evaluating curves for d=100, label_flip_p=0.2\n",
      "Position 20: memorization = 0.855, test = 0.776\n",
      "\n",
      "Evaluating checkpoints/checkpoint_d2000_B2000_R14_20241119_120146_step_300.pt\n",
      "\n",
      "Evaluating curves for d=2000, label_flip_p=0.2\n",
      "Position 20: memorization = 1.000, test = 0.700\n",
      "\n",
      "Evaluating checkpoints/checkpoint_d400_B400_R8_20241119_095941_step_300.pt\n",
      "\n",
      "Evaluating curves for d=400, label_flip_p=0.2\n",
      "Position 20: memorization = 0.910, test = 0.775\n",
      "\n",
      "Evaluating checkpoints/checkpoint_d600_B600_R9_20241119_095946_step_300.pt\n",
      "\n",
      "Evaluating curves for d=600, label_flip_p=0.2\n",
      "Position 20: memorization = 0.935, test = 0.788\n",
      "\n",
      "Evaluating checkpoints/checkpoint_d800_B800_R10_20241119_095958_step_300.pt\n",
      "\n",
      "Evaluating curves for d=800, label_flip_p=0.2\n",
      "Position 20: memorization = 0.957, test = 0.800\n",
      "\n",
      "Evaluating checkpoints/checkpoint_d1000_B1000_R11_20241119_100020_step_300.pt\n",
      "\n",
      "Evaluating curves for d=1000, label_flip_p=0.2\n",
      "Position 20: memorization = 0.971, test = 0.799\n",
      "\n",
      "Evaluating checkpoints/checkpoint_d1250_B1250_R12_20241119_100101_step_300.pt\n",
      "\n",
      "Evaluating curves for d=1250, label_flip_p=0.2\n",
      "Position 20: memorization = 0.983, test = 0.799\n",
      "\n",
      "Evaluating checkpoints/checkpoint_d1500_B1500_R12_20241119_100211_step_300.pt\n",
      "\n",
      "Evaluating curves for d=1500, label_flip_p=0.2\n",
      "Position 20: memorization = 0.989, test = 0.810\n",
      "\n",
      "Evaluating checkpoints/checkpoint_d2000_B2000_R14_20241119_120146_step_300.pt\n",
      "\n",
      "Evaluating curves for d=2000, label_flip_p=0.2\n",
      "Position 20: memorization = 0.997, test = 0.790\n",
      "Saved plot for label_flip_p=0.2 to plots/dimension_curves_N20_R0.3_p0.2.png\n",
      "\n",
      "Evaluating checkpoints/checkpoint_d100_B100_R5_20241119_095938_step_300.pt\n",
      "\n",
      "Evaluating curves for d=100, label_flip_p=0.2\n",
      "Position 20: memorization = 0.855, test = 0.776\n",
      "\n",
      "Evaluating checkpoints/checkpoint_d50_B50_R3_20241119_095938_step_300.pt\n",
      "\n",
      "Evaluating curves for d=50, label_flip_p=0.2\n",
      "Position 20: memorization = 0.801, test = 0.791\n",
      "\n",
      "Evaluating checkpoints/checkpoint_d100_B100_R5_20241119_095938_step_300.pt\n",
      "\n",
      "Evaluating curves for d=100, label_flip_p=0.2\n",
      "Position 20: memorization = 0.804, test = 0.799\n",
      "\n",
      "Evaluating checkpoints/checkpoint_d2000_B2000_R14_20241119_120146_step_300.pt\n",
      "\n",
      "Evaluating curves for d=2000, label_flip_p=0.2\n",
      "Position 20: memorization = 0.809, test = 0.796\n",
      "\n",
      "Evaluating checkpoints/checkpoint_d400_B400_R8_20241119_095941_step_300.pt\n",
      "\n",
      "Evaluating curves for d=400, label_flip_p=0.2\n",
      "Position 20: memorization = 0.800, test = 0.786\n",
      "\n",
      "Evaluating checkpoints/checkpoint_d600_B600_R9_20241119_095946_step_300.pt\n",
      "\n",
      "Evaluating curves for d=600, label_flip_p=0.2\n",
      "Position 20: memorization = 0.802, test = 0.795\n",
      "\n",
      "Evaluating checkpoints/checkpoint_d800_B800_R10_20241119_095958_step_300.pt\n",
      "\n",
      "Evaluating curves for d=800, label_flip_p=0.2\n",
      "Position 20: memorization = 0.802, test = 0.808\n",
      "\n",
      "Evaluating checkpoints/checkpoint_d1000_B1000_R11_20241119_100020_step_300.pt\n",
      "\n",
      "Evaluating curves for d=1000, label_flip_p=0.2\n",
      "Position 20: memorization = 0.800, test = 0.800\n",
      "\n",
      "Evaluating checkpoints/checkpoint_d1250_B1250_R12_20241119_100101_step_300.pt\n",
      "\n",
      "Evaluating curves for d=1250, label_flip_p=0.2\n",
      "Position 20: memorization = 0.804, test = 0.802\n",
      "\n",
      "Evaluating checkpoints/checkpoint_d1500_B1500_R12_20241119_100211_step_300.pt\n",
      "\n",
      "Evaluating curves for d=1500, label_flip_p=0.2\n",
      "Position 20: memorization = 0.804, test = 0.814\n",
      "\n",
      "Evaluating checkpoints/checkpoint_d2000_B2000_R14_20241119_120146_step_300.pt\n",
      "\n",
      "Evaluating curves for d=2000, label_flip_p=0.2\n",
      "Position 20: memorization = 0.802, test = 0.797\n",
      "Saved plot for label_flip_p=0.2 to plots/dimension_curves_N20_R0.6_p0.2.png\n"
     ]
    }
   ],
   "source": [
    "from classification_icl import ExperimentConfig, LinearTransformer, GaussianMixtureDataset\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import asdict\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "class CheckpointEvaluator:\n",
    "    \"\"\"Evaluator class for analyzing trained model checkpoints\"\"\"\n",
    "    \n",
    "    def __init__(self, checkpoint_dir: str, label_flips: Optional[List[float]] = [0.0, 0.2]):\n",
    "        self.checkpoint_dir = Path(checkpoint_dir)\n",
    "        self.label_flips = label_flips\n",
    "        \n",
    "    def load_checkpoint(self, checkpoint_path: str) -> Tuple[LinearTransformer, ExperimentConfig]:\n",
    "        \"\"\"Load model and config from checkpoint\"\"\"\n",
    "        checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "        config = ExperimentConfig(**asdict(checkpoint['config']))\n",
    "        model = LinearTransformer(config.d)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model.eval()\n",
    "        return model, config\n",
    "\n",
    "    def evaluate_risk_curves(\n",
    "        self,\n",
    "        model: LinearTransformer,\n",
    "        d: int,\n",
    "        max_seq_length: int,\n",
    "        R: Optional[float] = None,\n",
    "        num_samples: int = 2500,\n",
    "        label_flip_ps: Optional[List[float]] = None,\n",
    "        device: str = 'cpu'\n",
    "    ) -> Dict[str, Dict[str, np.ndarray]]:\n",
    "        \"\"\"\n",
    "        Evaluate model's performance curves including both means and standard errors.\n",
    "        \"\"\"\n",
    "        if label_flip_ps is None:\n",
    "            label_flip_ps = self.label_flips\n",
    "            \n",
    "        model = model.to(device)\n",
    "        results = {}\n",
    "        if R is None:\n",
    "            R = d ** 0.3\n",
    "        \n",
    "        for label_flip_p in label_flip_ps:\n",
    "            print(f\"\\nEvaluating curves for d={d}, label_flip_p={label_flip_p}\")\n",
    "            \n",
    "            dataset = GaussianMixtureDataset(\n",
    "                d=d,\n",
    "                N=max_seq_length,\n",
    "                B=num_samples,\n",
    "                R=R,\n",
    "                is_validation=True,\n",
    "                label_flip_p=label_flip_p\n",
    "            )\n",
    "            \n",
    "            context_x, context_y, _, _ = [t.to(device) for t in dataset[0]]\n",
    "            \n",
    "            memorization_accuracies = np.zeros((max_seq_length-1, num_samples))\n",
    "            test_accuracies = np.zeros((max_seq_length-1, num_samples))\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for k in range(1, max_seq_length):\n",
    "                    curr_context_x = context_x[:, :k]\n",
    "                    curr_context_y = context_y[:, :k]\n",
    "                    \n",
    "                    # Memorization accuracy (per example)\n",
    "                    mem_preds = model.compute_in_context_preds(curr_context_x, curr_context_y)\n",
    "                    mem_correct = (mem_preds == curr_context_y).float()\n",
    "                    memorization_accuracies[k-1] = mem_correct.mean(dim=1).cpu().numpy()\n",
    "                    \n",
    "                    # Test accuracy (per example)\n",
    "                    next_x = context_x[:, k:k+1, :]\n",
    "                    next_y = context_y[:, k:k+1]\n",
    "                    \n",
    "                    pred_logits = model(curr_context_x, curr_context_y, next_x.squeeze(1))\n",
    "                    test_preds = (pred_logits > 0).float()\n",
    "                    test_correct = (test_preds == next_y.squeeze(1)).float()\n",
    "                    test_accuracies[k-1] = test_correct.cpu().numpy()\n",
    "                    \n",
    "                    if k % 20 == 0:\n",
    "                        print(f\"Position {k}: memorization = {memorization_accuracies[k-1].mean():.3f}, test = {test_accuracies[k-1].mean():.3f}\")\n",
    "            \n",
    "            results[label_flip_p] = {\n",
    "                'memorization': {\n",
    "                    'mean': memorization_accuracies.mean(axis=1),\n",
    "                    'stderr': memorization_accuracies.std(axis=1) / np.sqrt(num_samples-1)\n",
    "                },\n",
    "                'test': {\n",
    "                    'mean': test_accuracies.mean(axis=1),\n",
    "                    'stderr': test_accuracies.std(axis=1) / np.sqrt(num_samples-1)\n",
    "                }\n",
    "            }\n",
    "            \n",
    "        return results\n",
    "\n",
    "    def plot_dimension_curves(self, results_by_d: Dict[int, Dict[float, Dict[str, Dict[str, np.ndarray]]]],  R_d_to_power: float = 0.3,\n",
    "                            sequence_length: int = 40, save_path: Optional[str] = None,\n",
    "                            label_flip_ps: Optional[List[float]] = None, force_y_range = False):\n",
    "        \"\"\"Plot separate accuracy vs dimension curves for each label flip probability\"\"\"\n",
    "        if label_flip_ps is None:\n",
    "            label_flip_ps = self.label_flips\n",
    "\n",
    "        plt.rcParams['text.usetex'] = False\n",
    "        plt.rcParams['mathtext.default'] = 'regular'\n",
    "\n",
    "        dimensions = sorted(results_by_d.keys())\n",
    "        seq_idx = sequence_length - 2\n",
    "        \n",
    "        mem_color = 'red'\n",
    "        test_color = 'blue'\n",
    "        opt_color = 'green'\n",
    "        \n",
    "        # Create separate plot for each label flip probability\n",
    "        for label_flip_p in label_flip_ps:\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            \n",
    "            mem_means = []\n",
    "            mem_errs = []\n",
    "            test_means = []\n",
    "            test_errs = []\n",
    "            \n",
    "            for d in dimensions:\n",
    "                curves = results_by_d[d][label_flip_p]\n",
    "                mem_means.append(curves['memorization']['mean'][seq_idx])\n",
    "                mem_errs.append(curves['memorization']['stderr'][seq_idx])\n",
    "                test_means.append(curves['test']['mean'][seq_idx])\n",
    "                test_errs.append(curves['test']['stderr'][seq_idx])\n",
    "            \n",
    "            mem_means = np.array(mem_means)\n",
    "            mem_errs = np.array(mem_errs)\n",
    "            test_means = np.array(test_means)\n",
    "            test_errs = np.array(test_errs)\n",
    "            plt.errorbar(dimensions, mem_means, yerr=1.96*mem_errs, \n",
    "                        color=mem_color, linestyle='--', linewidth=2,\n",
    "                        label='In-context train', capsize=3)\n",
    "            plt.errorbar(dimensions, test_means, yerr=1.96*test_errs,\n",
    "                        color=test_color, linestyle='-', linewidth=2,\n",
    "                        label='Test', capsize=3)\n",
    "            \n",
    "            optimal_acc = 1.0 - label_flip_p\n",
    "            plt.plot(dimensions, [optimal_acc] * len(dimensions), \n",
    "                    color=opt_color, linestyle='-.', linewidth=2, \n",
    "                    label=f'Optimal Test ({optimal_acc:.2f})')\n",
    "            \n",
    "            base_font = 11\n",
    "            if force_y_range:\n",
    "                plt.ylim(0.49, 1.01)\n",
    "            plt.xlabel('Input Dimension (d)', fontsize = base_font+1)\n",
    "            plt.ylabel('Accuracy', fontsize = base_font+1)\n",
    "            # plt.title(f'Performance vs Dimension\\n(R=d^{R_d_to_power}, Sequence Length = {sequence_length}, Label Flip = {label_flip_p})')\n",
    "\n",
    "            plt.title(f'Performance vs Dimension ($\\\\tilde R=d^{{{R_d_to_power}}}$)\\n(Sequence Length = {sequence_length}, Label Flip = {label_flip_p})', fontsize=14)\n",
    "            # plt.title(f'Performance vs Dimension ($R=d^{R_d_to_power}$)\\n(Sequence Length = {sequence_length}, Label Flip = {label_flip_p})', fontsize=14)\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.xticks(fontsize=base_font)\n",
    "            plt.yticks(fontsize=base_font)\n",
    "            plt.xscale('log')\n",
    "\n",
    "            # Check if bottom right area is crowded by looking at the final values\n",
    "            final_mem = mem_means[-1]  # Last memorization value\n",
    "            final_test = test_means[-1]  # Last test value\n",
    "            legend_threshold = 0.75  # Adjust this value to change sensitivity\n",
    "\n",
    "            if final_mem > legend_threshold and final_test > legend_threshold:\n",
    "                # If both lines are above threshold in bottom right, place legend there\n",
    "                plt.legend(loc='lower right', fontsize=11)\n",
    "            else:\n",
    "                # Otherwise use the default center right position\n",
    "                plt.legend(loc='center right', fontsize=11)\n",
    "            \n",
    "            if save_path:\n",
    "                base_path = Path(save_path)\n",
    "                # Ensure the parent directory exists\n",
    "                base_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "                \n",
    "                # Add .png extension if no extension is provided\n",
    "                if not base_path.suffix:\n",
    "                    base_path = base_path.with_suffix('.png')\n",
    "                    \n",
    "                flip_specific_path = base_path.parent / f\"{base_path.stem}_N{sequence_length}_R{R_d_to_power}_p{label_flip_p}{base_path.suffix}\"\n",
    "                plt.savefig(flip_specific_path, bbox_inches='tight', dpi=300)\n",
    "                print(f\"Saved plot for label_flip_p={label_flip_p} to {flip_specific_path}\")\n",
    "            else:\n",
    "                plt.show()\n",
    "                \n",
    "            plt.close()\n",
    "\n",
    "    def evaluate_checkpoint(self, checkpoint_file: str, max_seq_length: int, R: Optional[float]=None,\n",
    "                          label_flip_ps: Optional[List[float]]=None) -> Dict[int, Dict[float, Dict[str, np.ndarray]]]:\n",
    "        \"\"\"Evaluate a single checkpoint with specified maximum sequence length.\"\"\"\n",
    "        if label_flip_ps is None:\n",
    "            label_flip_ps = self.label_flips\n",
    "            \n",
    "        print(f\"\\nEvaluating {checkpoint_file}\")\n",
    "        model, config = self.load_checkpoint(checkpoint_file)\n",
    "        results = self.evaluate_risk_curves(\n",
    "            model=model,\n",
    "            d=config.d,\n",
    "            R=R,\n",
    "            max_seq_length=max_seq_length + 1,  # Add 1 to get desired sequence length\n",
    "            num_samples=2500,\n",
    "            label_flip_ps=label_flip_ps,\n",
    "            device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        )\n",
    "        return {config.d: results}\n",
    "\n",
    "def main():\n",
    "    evaluator = CheckpointEvaluator('checkpoints/', label_flips = [0.2])\n",
    "    max_seq_length = 20\n",
    "    \n",
    "    all_results = {}\n",
    "    dimensions = [10, 50, 100, 200, 400, 600, 800, 1000, 1250, 1500, 2000]\n",
    "\n",
    "    R_d_to_powers = [0.1, 0.3, 0.6]\n",
    "\n",
    "    for R_d_to_power in R_d_to_powers:\n",
    "        for d in dimensions:\n",
    "            matches = list(Path('checkpoints/').glob(f\"checkpoint_d{d}*.pt\"))\n",
    "            if matches:\n",
    "                R = d**R_d_to_power\n",
    "                # Use default label flips from evaluator\n",
    "                results = evaluator.evaluate_checkpoint(str(matches[0]), max_seq_length, R)\n",
    "                all_results.update(results)\n",
    "        \n",
    "        evaluator.plot_dimension_curves(all_results, sequence_length=max_seq_length, save_path=\"plots/dimension_curves.png\", R_d_to_power=R_d_to_power, force_y_range = True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synforward",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
